{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample code for multi-agent RAG with langGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    total_iterations: Optional[int] = None\n",
    "    input_feedback: Optional[str] = None  # Feedback from InputValidator\n",
    "    location_feedback: Optional[str] = None  # Feedback from LocationSelector\n",
    "    budget_feedback: Optional[str] = None  # Feedback from BudgetReviewer\n",
    "    schedule_feedback: Optional[str] = None  # Feedback from Scheduler\n",
    "    final_schedule: Optional[str] = None  # Final schedule\n",
    "    \n",
    "    # Additional fields for the user inputs\n",
    "    start_time: Optional[str] = None  # Start time\n",
    "    end_time: Optional[str] = None  # End time\n",
    "    indoor_outdoor: Optional[str] = None  # Indoor or outdoor preference\n",
    "    country: Optional[int] = None  # Country\n",
    "    budget: Optional[float] = None  # User's budget\n",
    "    food_preference: Optional[str] = None  # Food preferences (e.g., vegetarian, etc.)\n",
    "    activity_preference: Optional[str] = None  # Activity preference (e.g., relaxing, adventurous)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common LLM agent\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.model_url = 'https://api.openai.com/v1/chat/completions'\n",
    "        self.api_key = os.getenv('API_KEY')\n",
    "        self.headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {self.api_key}'\n",
    "        }\n",
    "        self.max_tokens = 1000\n",
    "\n",
    "    def get_llm_response(self, prompt):\n",
    "        data = {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": self.max_tokens\n",
    "        }\n",
    "\n",
    "        llm_response = \"\"\n",
    "        response = requests.post(self.model_url, headers=self.headers, json=data)\n",
    "        if response.status_code == 200:\n",
    "            llm_response = response.json()['choices'][0]['message']['content']\n",
    "        else:\n",
    "            print(\"Error:\", response.status_code, response.text)\n",
    "\n",
    "        return llm_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input validator agent\n",
    "class InputValidator:\n",
    "    def __init__(self, llm_caller):\n",
    "        self.llm_caller = llm_caller\n",
    "        self.reviewer_prompt = (\n",
    "            \"Please validate the following user inputs.\\n\"\n",
    "            \"Return a structured list of valid or invalid inputs based on the user response. \"\n",
    "            \"Consider the following factors for location suggestions:\\n\"\n",
    "            \"1. Start time (Time the date should start)\\n\"\n",
    "            \"2. End time (Time the date should end)\\n\"\n",
    "            \"3. Indoor or outdoor preference\\n\"\n",
    "            \"4. Country for the date (e.g., France, Singapore, etc.)\\n\"\n",
    "            \"5. Total budget set for the date\\n\"\n",
    "            \"6. Food preferences (e.g Vegetarian, etc.)\\n\"\n",
    "            \"7. Activity preferences (e.g., relaxing, adventurous)\\n\"\n",
    "            \"Inputs: {}\"\n",
    "        )\n",
    "# Additional fields for the user inputs\n",
    "    start_time: Optional[str] = None  # Start time\n",
    "    end_time: Optional[str] = None  # End time\n",
    "    indoor_outdoor: Optional[str] = None  # Indoor or outdoor preference\n",
    "    country: Optional[int] = None  # Country\n",
    "    budget: Optional[float] = None  # User's budget\n",
    "    food_preference: Optional[str] = None  # Food preferences (e.g., vegetarian, etc.)\n",
    "    activity_preference: Optional[str] = None  # Activity preference (e.g., relaxing, adventurous)\n",
    "    \n",
    "    \n",
    "    def validate_input(self, state):\n",
    "        # Collect the necessary inputs from the state\n",
    "        start_time = state.get('start_time', 'anytime')  # Start time\n",
    "        end_time = state.get('end_time', 'anytime')  # End time\n",
    "        indoor_outdoor = state.get('indoor_outdoor', 'both')  # Indoor or outdoor preference\n",
    "        country = state.get('country', 'Singapore')  # Max travel distance in km\n",
    "        budget = state.get('budget', 200.0)  # User's budget range\n",
    "        food_preference = state.get('food_preferences', '')  # Food preferences (e.g., vegetarian, etc.)\n",
    "        activity_type = state.get('activity_type', 'relaxing')  # Activity preference (fun, adventurous, etc.)\n",
    "\n",
    "        # Prepare the input prompt with collected user preferences\n",
    "        user_input = (\n",
    "            f\"Start Time: {start_time}, End Time: {end_time}, \"\n",
    "            f\"Indoor/Outdoor Preference: {indoor_outdoor}, \"\n",
    "            f\"Country of activities: {country}, \"\n",
    "            f\"Budget: {budget}, \"\n",
    "            f\"Food Preference: {food_preference}, \"\n",
    "            f\"Activity Type: {activity_type}, \"\n",
    "        )\n",
    "\n",
    "        # Get the agent's feedback using the updated prompt\n",
    "        agent_feedback = self.llm_caller.get_llm_response(self.reviewer_prompt.format(user_input))\n",
    "        print(\"Input Feedback:\", agent_feedback)\n",
    "        # Add the feedback and return the updated state\n",
    "        return {\n",
    "            'input_feedback': agent_feedback,  # Save the feedback here\n",
    "            'total_iterations': state.get('total_iterations', 0),\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'indoor_outdoor': indoor_outdoor,\n",
    "            'country': country,\n",
    "            'budget': budget,\n",
    "            'food_preference': food_preference,\n",
    "            'activity_type': activity_type,\n",
    "        }\n",
    "\n",
    "# Scheduling agent\n",
    "class SchedulingAgent:\n",
    "    def __init__(self, llm_caller):\n",
    "        self.llm_caller = llm_caller\n",
    "        self.scheduling_prompt = (\n",
    "            \"Create a schedule for a date considering the following details: \"\n",
    "            \"Country: {country}, Start Time: {start_time}, End Time: {end_time}, \"\n",
    "            \"Activity Preferences: {activity_preference}. Ensure the plan is feasible and aligns with the provided inputs.\"\n",
    "            \"Input the specific locations if available from location feedback: {location_feedback} \" \n",
    "            \"If not, just general type of activities E.g. Dinner, Lunch, Supper, outdoor activity, indoor activity, etc. .\"\n",
    "            \"You may take budget feedback into considerations if available: {budget_feedback}\"\n",
    "        )\n",
    "\n",
    "    def schedule_date(self, state: GraphState) -> str:\n",
    "        \"\"\"\n",
    "        Generate or adjust a schedule based on the current state.\n",
    "\n",
    "        Args:\n",
    "            state (GraphState): The current state of the planning process.\n",
    "\n",
    "        Returns:\n",
    "            str: Feedback or proposed schedule from the agent.\n",
    "        \"\"\"\n",
    "        # Extract relevant details from the state\n",
    "        country = state.get(\"country\", \"Singapore\")\n",
    "        start_time = state.get(\"start_time\", \"N/A\")\n",
    "        end_time = state.get(\"end_time\", \"N/A\")\n",
    "        activity_preference = state.get(\"activity_preference\", \"any\")\n",
    "        location_feedback = state.get(\"location_feedback\", \"No specific location yet\").strip()\n",
    "        budget_feedback = state.get(\"budget_feedback\", \"No budget feedback yet\").strip()\n",
    "        \n",
    "        # Format the prompt for the LLM\n",
    "        formatted_prompt = self.scheduling_prompt.format(\n",
    "            country=country,\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            activity_preference=activity_preference,\n",
    "            location_feedback=location_feedback,\n",
    "            budget_feedback=budget_feedback,\n",
    "        )\n",
    "\n",
    "        # Call the LLM for feedback or a schedule proposal\n",
    "        agent_feedback = self.llm_caller.get_llm_response(formatted_prompt)\n",
    "        print(f\"Schedule Feedback for loop {state.get('total_iterations')}: {agent_feedback}\")\n",
    "        # Add feedback to the state and return updated state\n",
    "        return {\n",
    "            'original_query': state.get('original_query', ''),\n",
    "            'schedule_feedback': agent_feedback,  # Save the feedback here\n",
    "            'total_iterations': state.get('total_iterations', 0) + 1 # Increment everytime it goes back to scheduler\n",
    "        }\n",
    "\n",
    "# Location selection agent\n",
    "class LocationSelector:\n",
    "    def __init__(self, llm_caller):\n",
    "        self.llm_caller = llm_caller\n",
    "        self.location_prompt = (\n",
    "            \"Given the schedule feedback, if available from: {schedule_feedback}.\\n\"\n",
    "            \"And given the budget feedback, if available from: {budget_feedback}.\\n\"\n",
    "            \"Select suitable locations to fit into the schedule based on the user's preferences.\\n\"\n",
    "            \"Provide a brief location feedback for each location chosen. \"\n",
    "            \"The user's preferences are: {user_input}.\\n\"\n",
    "            \n",
    "        )\n",
    "    def select_location(self, state):\n",
    "        # Retrieve the necessary values from the state\n",
    "        indoor_outdoor = state.get('indoor_outdoor', '')\n",
    "        food_preference = state.get('food_preference', '')\n",
    "        activity_preference = state.get('activity_preference', '')\n",
    "        \n",
    "\n",
    "        # Prepare the user input for location selection based on their preferences\n",
    "        user_input = (\n",
    "            f\"Indoor/Outdoor Preference: {indoor_outdoor}, \"\n",
    "            f\"Food Preferences: {food_preference}, \"\n",
    "            f\"Activity Preferences: {activity_preference}\"\n",
    "        )\n",
    "        schedule_feedback = state.get('schedule_feedback', '').strip()\n",
    "        budget_feedback = state.get('budget_feedback', '').strip()\n",
    "        # Format the prompt for the LLM\n",
    "        formatted_prompt = self.location_prompt.format(\n",
    "            user_input=user_input,\n",
    "            schedule_feedback=schedule_feedback,\n",
    "            budget_feedback=budget_feedback\n",
    "        )\n",
    "\n",
    "        agent_feedback = self.llm_caller.get_llm_response(self.location_prompt.format(formatted_prompt))\n",
    "        print(f\"Location Feedback for loop {state.get('total_iterations')}: {agent_feedback}\")\n",
    "        # Add feedback to the state and return updated state\n",
    "        return {\n",
    "            'original_query': state.get('original_query', ''),\n",
    "            'location_feedback': agent_feedback,  # Save the feedback here\n",
    "            'total_iterations': state.get('total_iterations', 0)\n",
    "        }\n",
    "\n",
    "        \n",
    "# Budget review agent\n",
    "class BudgetAgent:\n",
    "    def __init__(self, llm_caller):\n",
    "        self.llm_caller = llm_caller\n",
    "        self.budget_prompt = (\n",
    "            \"Evaluate if the proposed schedule and locations fit within the user's budget.\\n\"\n",
    "            \"Budget: {budget}.\\n\"\n",
    "            \"Schedule Feedback if available: {schedule_feedback}.\\n\"\n",
    "            \"Location Feedback if available: {location_feedback}.\\n\"\n",
    "            \"Consider additional costs such as transportation, meals, and activity fees.\\n\"\n",
    "            \"Return your analysis and recommendations:\\n\"\n",
    "            \"1. Whether the budget is sufficient.\\n\"\n",
    "            \"2. Suggestions for adjustments if needed.\\n\"\n",
    "        )\n",
    "\n",
    "    def review_budget(self, state: GraphState) -> str:\n",
    "        \"\"\"\n",
    "        Evaluate the current state against the user's budget and provide feedback.\n",
    "\n",
    "        Args:\n",
    "            state (GraphState): The current planning state.\n",
    "\n",
    "        Returns:\n",
    "            str: Feedback on the budget and recommendations.\n",
    "        \"\"\"\n",
    "        # Extract relevant details from the state\n",
    "        budget = state.get(\"budget\", 200.0)  # User's specified budget\n",
    "        schedule_feedback = state.get(\"schedule_feedback\", \"No schedule provided.\").strip()\n",
    "        location_feedback = state.get(\"location_feedback\", \"No locations provided.\").strip()\n",
    "\n",
    "        # Format the prompt for the LLM\n",
    "        formatted_prompt = self.budget_prompt.format(\n",
    "            budget=budget,\n",
    "            schedule_feedback=schedule_feedback,\n",
    "            location_feedback=location_feedback,\n",
    "        )\n",
    "\n",
    "        # Call the LLM for budget analysis\n",
    "        agent_feedback = self.llm_caller.get_llm_response(formatted_prompt)\n",
    "        print(f\"Budget Feedback for loop {state.get('total_iterations')}: {agent_feedback}\")\n",
    "        # Add feedback to the state and return updated state\n",
    "        return {\n",
    "            'original_query': state.get('original_query', ''),\n",
    "            'budget_feedback': agent_feedback,  # Save the feedback here\n",
    "            'total_iterations': state.get('total_iterations', 0)\n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, llm_caller):\n",
    "        self.llm_caller = llm_caller\n",
    "        self.evaluator_prompt = (\n",
    "            \"You are an evaluator tasked with assessing the feasibility of a date plan based on the following constraints:\\n\"\n",
    "            \"1. Budget feedback: {budget_feedback}\\n\"\n",
    "            \"2. User exact budget: {budget}\\n\"\n",
    "            \"3. Location Feedback: {location_feedback}\\n\"\n",
    "            \"4. Schedule Feedback: {schedule_feedback}\\n\\n\"\n",
    "            \"Please answer the following:\\n\"\n",
    "            \"a) Does the budget align with the proposed locations and activities?\\n\"\n",
    "            \"b) Are the selected locations feasible based on the schedule?\\n\"\n",
    "            \"c) Is the overall plan aligned with the user's preferences and constraints?\\n\\n\"\n",
    "            \"Only output 'Yes' if all conditions are met and the plan is feasible; otherwise, output 'No'.\"\n",
    "        )\n",
    "\n",
    "    def evaluate_plan(self, state):\n",
    "        \"\"\"\n",
    "        Evaluate the feasibility of the current date plan.\n",
    "\n",
    "        Args:\n",
    "            state (GraphState): The current state containing feedback from agents.\n",
    "\n",
    "        Returns:\n",
    "            str: The name of the next agent to proceed with ('scheduling_agent' or 'input_validator').\n",
    "        \"\"\"\n",
    "        # Retrieve feedback from the state\n",
    "        budget_feedback = state.get('budget_feedback', '').strip()\n",
    "        location_feedback = state.get('location_feedback', '').strip()\n",
    "        schedule_feedback = state.get('schedule_feedback', '').strip()\n",
    "        # Retrieve user constraints for detailed evaluation\n",
    "        budget = state.get('budget', 0)\n",
    "        \n",
    "\n",
    "        # Prepare the evaluation prompt\n",
    "        formatted_prompt = self.evaluator_prompt.format(budget, budget_feedback, location_feedback, schedule_feedback)\n",
    "\n",
    "        # Call the LLM to assess the feasibility of the plan\n",
    "        evaluator_response = self.llm_caller.get_llm_response(formatted_prompt)\n",
    "\n",
    "        # Determine next step based on evaluator response and constraints\n",
    "        if evaluator_response.lower() == 'yes':\n",
    "            return 'finalize_plan'  # All constraints satisfied; ready to finalize\n",
    "        elif state.get('total_iterations', 0) > 3:\n",
    "            return 'finalize_plan'  # process ends\n",
    "        else:\n",
    "            return 'scheduling_agent'  # Revisit input validation for adjustments\n",
    "        \n",
    "class FinalPlan:\n",
    "    def __init__(self, llm_caller):\n",
    "        self.llm_caller = llm_caller\n",
    "        self.final_plan_prompt = (\n",
    "            \"You are a planner tasked with creating a final date plan based on the following information:\\n\"\n",
    "            \"1. Location Feedback: {location_feedback}\\n\"\n",
    "            \"2. Schedule Feedback: {schedule_feedback}\\n\"\n",
    "            \"3. Budget Feedback: {budget_feedback}\\n\"\n",
    "            \"Ensure that the the locations fit into the schedule and the budget\"\n",
    "        )\n",
    "\n",
    "    def finalize_plan(self, state):\n",
    "        # Retrieve feedback from the state\n",
    "        location_feedback = state.get('location_feedback', '').strip()\n",
    "        schedule_feedback = state.get('schedule_feedback', '').strip()\n",
    "        budget_feedback = state.get('budget_feedback', '').strip()\n",
    "\n",
    "        # Prepare the final plan prompt\n",
    "        formatted_prompt = self.final_plan_prompt.format(location_feedback, schedule_feedback, budget_feedback)\n",
    "\n",
    "        # Call the LLM to create the final plan\n",
    "        final_plan = self.llm_caller.get_llm_response(formatted_prompt)\n",
    "        print(final_plan)\n",
    "        # Return the finalized plan\n",
    "        return {f\"Final plan {final_plan}, No. of iterations: {state.get('total_iterations')}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10b553fd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph import END\n",
    "\n",
    "# Instantiate the workflow and LLM\n",
    "dating_review_workflow = StateGraph(GraphState)\n",
    "llm_caller = LLM()\n",
    "\n",
    "# Define agents\n",
    "input_validator = InputValidator(llm_caller=llm_caller)\n",
    "location_selector = LocationSelector(llm_caller=llm_caller)\n",
    "scheduling_agent = SchedulingAgent(llm_caller=llm_caller)\n",
    "budget_reviewer = BudgetAgent(llm_caller=llm_caller)\n",
    "evaluator = Evaluator(llm_caller=llm_caller)\n",
    "finalize_plan = FinalPlan(llm_caller=llm_caller)\n",
    "\n",
    "# Add nodes for agents\n",
    "dating_review_workflow.add_node(\"input_validator\", input_validator.validate_input)\n",
    "dating_review_workflow.add_node(\"location_selector\", location_selector.select_location)\n",
    "dating_review_workflow.add_node(\"scheduling_agent\", scheduling_agent.schedule_date)\n",
    "dating_review_workflow.add_node(\"budget_reviewer\", budget_reviewer.review_budget)\n",
    "dating_review_workflow.add_node(\"evaluator\", evaluator.evaluate_plan)\n",
    "dating_review_workflow.add_node(\"finalize_plan\", finalize_plan.finalize_plan)\n",
    "\n",
    "# Set entry point\n",
    "dating_review_workflow.set_entry_point(\"input_validator\")\n",
    "\n",
    "# Add edges for transitions, including evaluator\n",
    "dating_review_workflow.add_edge(\"input_validator\", \"location_selector\")\n",
    "dating_review_workflow.add_edge(\"location_selector\", \"scheduling_agent\")\n",
    "dating_review_workflow.add_edge(\"scheduling_agent\", \"budget_reviewer\")\n",
    "dating_review_workflow.add_edge(\"budget_reviewer\", \"evaluator\")\n",
    "\n",
    "dating_review_workflow.add_conditional_edges(\n",
    "    \"budget_reviewer\",\n",
    "    evaluator.evaluate_plan,\n",
    "    {\n",
    "        \"scheduling_agent\",\n",
    "        \"finalize_plan\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add END condition for budget reviewer (final step before evaluation)\n",
    "dating_review_workflow.add_edge(\"finalize_plan\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Feedback: Based on the user inputs provided, we can validate each aspect according to the criteria specified. Below is a structured list of the valid and invalid inputs:\n",
      "\n",
      "### Valid/Invalid Inputs:\n",
      "1. **Start Time**: \n",
      "   - **Input**: \"anytime\"\n",
      "   - **Validation**: Invalid (should specify a specific time)\n",
      "\n",
      "2. **End Time**: \n",
      "   - **Input**: \"anytime\"\n",
      "   - **Validation**: Invalid (should specify a specific time)\n",
      "\n",
      "3. **Indoor or Outdoor Preference**: \n",
      "   - **Input**: \"Indoor or outdoor\"\n",
      "   - **Validation**: Invalid (should specify either 'Indoor' or 'Outdoor')\n",
      "\n",
      "4. **Country for the Date**: \n",
      "   - **Input**: \"Singapore\"\n",
      "   - **Validation**: Valid \n",
      "\n",
      "5. **Total Budget Set for the Date**: \n",
      "   - **Input**: 200\n",
      "   - **Validation**: Valid (assuming it's a positive integer, which is common for a budget)\n",
      "\n",
      "6. **Food Preferences**: \n",
      "   - **Input**: \"\" (blank)\n",
      "   - **Validation**: Invalid (should specify food preferences)\n",
      "\n",
      "7. **Activity Preferences**: \n",
      "   - **Input**: \"relaxing\"\n",
      "   - **Validation**: Valid \n",
      "\n",
      "### Summary:\n",
      "- **Valid Inputs**: \n",
      "  - Country for the Date: Singapore\n",
      "  - Total Budget Set for the Date: 200\n",
      "  - Activity Preferences: relaxing\n",
      "\n",
      "- **Invalid Inputs**: \n",
      "  - Start Time: anytime\n",
      "  - End Time: anytime\n",
      "  - Indoor or Outdoor Preference: Indoor or outdoor\n",
      "  - Food Preferences: (blank)\n",
      "\n",
      "### Conclusion:\n",
      "To improve these inputs, the user should specify specific start and end times, choose between indoor or outdoor, provide food preferences, and clarify the indoor/outdoor preference.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'schedule_feedback'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Execute the workflow\u001b[39;00m\n\u001b[1;32m     10\u001b[0m result \u001b[38;5;241m=\u001b[39m dating_review_workflow\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m---> 12\u001b[0m conversation \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecursion_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(conversation)\n",
      "File \u001b[0;32m~/miniconda3/envs/dating/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1927\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1926\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1927\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dating/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1647\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1641\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1647\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1654\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dating/lib/python3.11/site-packages/langgraph/pregel/runner.py:104\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    102\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/dating/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, writer)\u001b[0m\n\u001b[1;32m     38\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dating/lib/python3.11/site-packages/langgraph/utils/runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/dating/lib/python3.11/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[39], line 149\u001b[0m, in \u001b[0;36mLocationSelector.select_location\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Format the prompt for the LLM\u001b[39;00m\n\u001b[1;32m    143\u001b[0m formatted_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_prompt\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    144\u001b[0m     user_input\u001b[38;5;241m=\u001b[39muser_input,\n\u001b[1;32m    145\u001b[0m     schedule_feedback\u001b[38;5;241m=\u001b[39mschedule_feedback,\n\u001b[1;32m    146\u001b[0m     budget_feedback\u001b[38;5;241m=\u001b[39mbudget_feedback\n\u001b[1;32m    147\u001b[0m )\n\u001b[0;32m--> 149\u001b[0m agent_feedback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_caller\u001b[38;5;241m.\u001b[39mget_llm_response(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation_prompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatted_prompt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation Feedback for loop \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_iterations\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_feedback\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Add feedback to the state and return updated state\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'schedule_feedback'"
     ]
    }
   ],
   "source": [
    "# Orchestrator to execute the workflow\n",
    "state = GraphState(\n",
    "    total_iterations=0,  # Initialize iteration counter\n",
    "    budget=200,  # Example user input\n",
    "    indoor_outdoor=\"Indoor or outdoor\",\n",
    "    activity_preference=\"relaxing\",\n",
    ")\n",
    "\n",
    "# Execute the workflow\n",
    "result = dating_review_workflow.compile()\n",
    "\n",
    "conversation = result.invoke(state, {\"recursion_limit\":100})\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dating",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
